{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load in the Hu & Liu (2004) word dictionary\n",
    "negative_words = open('negative-words.txt', 'r').read()\n",
    "negative_words = negative_words.split('\\n')\n",
    "positive_words = open('positive-words.txt', 'r').read()\n",
    "positive_words = positive_words.split('\\n')\n",
    "word_list = negative_words + positive_words\n",
    "word_list = list(set(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews_data = json.load(open(\"cleaned_reviews_subset.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print \"Topic %d:\" % (topic_idx)\n",
    "        print \" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ohio_reviews = []\n",
    "ohio_stars = []\n",
    "for review in reviews_data['OH']:\n",
    "    ohio_reviews.append(review['text'])\n",
    "    ohio_stars.append(review['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load in the Hu & Liu (2004) word dictionary\n",
    "negative_words = open('negative-words.txt', 'r').read()\n",
    "negative_words = negative_words.split('\\n')\n",
    "positive_words = open('positive-words.txt', 'r').read()\n",
    "positive_words = positive_words.split('\\n')\n",
    "word_list = negative_words + positive_words\n",
    "word_list = list(set(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'artsy', u'arturo', u'artwork', u'arugula', u'ary']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[1000:1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "fun warm cheap unfortunately weird awful ridiculously favor cute shake\n",
      "Topic 1:\n",
      "good like pretty better bad nice work great wrong bland\n",
      "Topic 2:\n",
      "cold horrible disgusting hype crap correct stuck regret overwhelming lacked\n",
      "Topic 3:\n",
      "modern shit blind devoid snobby uneven detract fuck ghetto vomit\n",
      "Topic 4:\n",
      "promises refuse amenable patronize burns hurts safely lure perplexed danger\n",
      "Topic 5:\n",
      "bomb wasted joy celebration pretend disrespectful bullshit hilarious peaceful strongest\n",
      "Topic 6:\n",
      "consistently comfortable cons expensive picky boring pros falls annoying happily\n",
      "Topic 7:\n",
      "pricey cheaper creative refreshing noisy worry greatest neat romantic charming\n",
      "Topic 8:\n",
      "inflated novelty grisly finer suffice scant qualms accuse abomination unnatural\n",
      "Topic 9:\n",
      "reasonably pokey quiet lover bizarre steady dissatisfied thinner smelling complements\n",
      "Topic 10:\n",
      "best hot love sweet good delicious like fresh fantastic fast\n",
      "Topic 11:\n",
      "prosperity divine innovative modest weirdly lying struggling fiery killing annoyingly\n",
      "Topic 12:\n",
      "rich disappointment smelled delicate decadent forbidden brilliant misleading standout shock\n",
      "Topic 13:\n",
      "loud thank popular fat issue worked crisp bother smoke available\n",
      "Topic 14:\n",
      "afford sexy tolerable audacity rumor pale overrun offend ranting succeeds\n",
      "Topic 15:\n",
      "excited works gross doubt inexpensive trust killer burned yay fave\n",
      "Topic 16:\n",
      "properly stumbled elegant adore successful remarkable exquisite cheerful ugly blessing\n",
      "Topic 17:\n",
      "fried fine greasy golden dirty split clearly hot incredibly goodness\n",
      "Topic 18:\n",
      "sick fabulous complimentary jam boiling ignore notably meager robust ease\n",
      "Topic 19:\n",
      "like liked won terrible problem easy right bad dark die\n",
      "Topic 20:\n",
      "great good nice delicious friendly best amazing love like excellent\n",
      "Topic 21:\n",
      "decent lack polite helped cramped liking concerned hassle lie freezing\n",
      "Topic 22:\n",
      "slow rude sorry like fair overpriced mistake lacking prompt fine\n",
      "Topic 23:\n",
      "upscale classy falling insanely crushed complement quieter redeem regretted dissapointed\n",
      "Topic 24:\n",
      "loved issues knowledgeable pan funny wise ample complaining beware plentiful\n"
     ]
    }
   ],
   "source": [
    "#View the top words in the LDA representation\n",
    "no_top_words = 10\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "display_topics(lda_fit, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/Users/robertsonwang/anaconda2/lib/python2.7/site-packages/sklearn/decomposition/online_lda.py:508: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Train a Random Forest Classifier on the LDA input matrix\n",
    "vectorizer = CountVectorizer(stop_words='english', vocabulary = word_list)\n",
    "tf = vectorizer.fit_transform(ohio_reviews)\n",
    "lda = LatentDirichletAllocation(n_topics=50).fit_transform(tf)\n",
    "lda_fit = LatentDirichletAllocation(n_topics=50).fit(tf)\n",
    "#Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(lda, ohio_stars, test_size=0.2)\n",
    "#Create a decision tree classifier object\n",
    "lda_classifier = svm.SVC(kernel='linear')\n",
    "#kernel='sigmoid'\n",
    "#Train the Decision Forest Classifier\n",
    "lda_classifier.fit(X_train, y_train)\n",
    "#Predict on the test set\n",
    "test_prediction = lda_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.473526473526\n",
      "0.444969595819\n",
      "[[ 97   1   0  19   6]\n",
      " [ 53   3   0  39  14]\n",
      " [ 36   1   0  79  19]\n",
      " [ 21   0   0 181  83]\n",
      " [ 20   0   0 136 193]]\n"
     ]
    }
   ],
   "source": [
    "#Print the Accuracy\n",
    "print accuracy_score(y_test, test_prediction)\n",
    "#Print the Precision\n",
    "print precision_score(y_test, test_prediction, average='weighted')\n",
    "#Print the confusion matrix\n",
    "print confusion_matrix(y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train a linear support vector machine on the tf-idf input matrix using the H&L dictionary\n",
    "tf_vectorizer = TfidfVectorizer(vocabulary = word_list)\n",
    "tf_features = tf_vectorizer.fit_transform(ohio_reviews)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_features, ohio_stars, test_size=0.2)\n",
    "#Create a decision tree classifier object\n",
    "tf_classifier = svm.SVC(kernel='linear')\n",
    "#Train the Decision Forest Classifier\n",
    "tf_classifier.fit(X_train, y_train)\n",
    "#Predict on the test set\n",
    "test_prediction = tf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508491508492\n",
      "0.489525644744\n",
      "[[ 80  20   4  12   5]\n",
      " [ 27  27  17  26   6]\n",
      " [ 19  15  27  61  26]\n",
      " [ 10   2  20 122 128]\n",
      " [  8   2   2  82 253]]\n"
     ]
    }
   ],
   "source": [
    "#Print the Accuracy\n",
    "print accuracy_score(y_test, test_prediction)\n",
    "#Print the Precision\n",
    "print precision_score(y_test, test_prediction, average='weighted')\n",
    "#Print the confusion matrix\n",
    "print confusion_matrix(y_test, test_prediction)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
