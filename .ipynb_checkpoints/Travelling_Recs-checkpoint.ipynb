{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "We want to recommend restaurants that the user will **like** based off that users existing reviews. We will do so by building a recommendation system that predicts whether a user will like a restaurant on a binary scale (good or bad).\n",
    "\n",
    "There are a couple of scenarios that we're trying to capture when recommending a good restaurant:\n",
    "\n",
    "1. A restaurant that has a terrible rating but for some reason the user loves it\n",
    "2. A restaurant that has a terrible rating and the user also hates it\n",
    "3. A restaurant that has a really good rating but for some reason the user doesn't really like it\n",
    "4. A restaurant that has a really good rating and the user loves it\n",
    "\n",
    "We want to recommend restaurants that match scenarios 1 and 4 and filter out for scenarios 2 and 3. We try to do this via the below hypotheses. The general idea is that we can capture the first portion of each scenario, \"A restaurant that has [blank] rating\", using linguistic tone. This is embodied in Hypothesis 2, where we define linguistic tone to be the negative and positive word categories in the Hu and Liu (2004) word dictionary. Hypothesis 1 tries to capture the second part of each scenario, \"the user feels [blank] about it\", by using unsupervised machine learning methods trained on each users specific syntax.\n",
    "\n",
    "We can interpret the weight that we place on Hypothesis 2 as the importance we place on linguistic tone and the weight on Hypothesis 1 as the importance we place on the users word choice.\n",
    "\n",
    "For more information see:\n",
    "\n",
    "* [A Yelp Recommendation System](https://www.cs.cornell.edu/~rahmtin/files/YelpClassProject.pdf)\n",
    "* [Original LDA paper](http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)\n",
    "* [2013 Yelp RecSys Kaggle Competition](https://www.kaggle.com/c/yelp-recsys-2013)\n",
    "* [2013 Yelp RecSys Kaggle Competition Runner Up Recommendation System](https://kaggle2.blob.core.windows.net/forum-message-attachments/9102/vsu_RecSys2013.pdf) \n",
    "* [Hu & Liu (2004)](https://www.cs.uic.edu/~liub/publications/kdd04-revSummary.pdf)\n",
    "\n",
    "Note: The method presented below is novel in the sense that we do not rely on restaurant descriptors, but only on the text of each users review. Although the inputs are different, the classification methods are similiar and we should expect similiar results if text is as good of a predictor as restaurant attributes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotheses\n",
    "We create our recommendation using the following hypotheses: \n",
    "\n",
    "**Hyptohesis 1**: The user's _word choice_ in his review are correlated with the kinds of restaurants that the user likes to visit and the types of food that the user likes to consume.\n",
    "\n",
    "**Hyptohesis 2**: The _tone_ of a user's review is correlated with the kinds of restaurants that the user likes to visit and the types of food that the user likes to consume.\n",
    "\n",
    "If the first hypothesis is true, then a user ought to like a restaurant that has reviews that use many of the same word choices. Word choice here means how a word is placed within a document. For example, \"The Thai food here is disgusting\" has a starkly different word choice than \"I love the amazing Thai food here\". To capture this, we use LDA to create a matrix representation of each review. The topic loadings are selected based on a mixture methodology between the top coefficients in a tf-idf representation of the user reviews and the top unique words in the user's reviews. We train on the reviews of new restaurants. Next, we use machine learning algorithms (detailed below) to classify user reviews into new restaurants. \n",
    "\n",
    "If the second hypothesis is true, then a user ought to like a restaurant that has reviews that have the same tone that she uses to describe restaurants that she likes. We define \"tonally similiar\" here to mean that the user's review, represented as a tf-idf matrix, has many of the same positive & negative word usage as the reviews of the new restaurant. Positive & negative words are defined using the Hu & Liu (2004) Yelp Dictionary. Next, we use machine learning algorithms (detailed below) to classify user reviews into new restaurants. \n",
    "\n",
    "With both hypotheses, the end result is that we try to predict which new restaurant a user's review was classified as most likely to be describing.\n",
    "\n",
    "A priori, our weights on the first hypothesis is 0.6 and our weight on the second hypothesis is 0.4 We can update these weights via user feedback. Specifically, we can define the following loss function and iterate through hypothesis weights until we minimize the loss. Ideally, we could get user feedback from these recommendations, adjust our weights, then get more feedback in an iterative attempt at minimizing the loss function. \n",
    "\n",
    "$$RMSE(x_{1}, x_{2}) =  \\sum_{i=1}^{N} \\sqrt{\\frac{(y_{i, pred}(x_{1}, x_{2}) - y_{i, actual})^{2}}{N}}$$\n",
    "\n",
    "Note, this function is analagous to the mean squared error used in the 2013 Yelp RecSys challenge:\n",
    "\n",
    "$$RMSE =  \\sum_{i=1}^{N} \\sqrt{\\frac{(y_{i, pred} - y_{i, actual})^{2}}{N}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 1 Algorithm Sketch:\n",
    "\n",
    "The goal of this algorithm sketch is to create a classification scheme using Hypothesis 1. We create a 10-word topic loading using a combination of top unique words and the top words in a given set of user reviews as defined by tf-idf. Next, we use LDA to represent the reviews in $Y_{s}$ and $B$ as dense matrices. We run classifcation algorithms on these matrices.\n",
    "\n",
    "Let B be the set of user reviews. Let $Y_{s}$ be a set of reviews in a given location, s. \n",
    "\n",
    "The elements of $Y_{s}$ and $B$ are characterized by the tuple $(t, r, R)$ where:\n",
    "\n",
    "$t = \\text{text}, r = \\text{rating}, R = \\text{Restaurant ID}$\n",
    "\n",
    "We want a mapping such that $f(B): B \\rightarrow \\text{Most similiar R in } Y_{s}$\n",
    "\n",
    "We propose the following algorithm:\n",
    "1. **Build**:\n",
    "    1. For B, create the following lists:\n",
    "    \n",
    "    ```python\n",
    "    Good_User_Reviews = [review for review in B if rating(review) >= 4]\n",
    "    Bad_User_reviews = [review for review in B if rating(review) < 4]\n",
    "\n",
    "    Good_User_Words = [review.split(' ') for review in Good_User_Reviews]\n",
    "    Bad_User_Words = [review.split(' ') for review in Good_User_Reviews]\n",
    "    Good_User_Words = set([word for review in Good_Words for word in review])\n",
    "    Bad_User_Words = set([word for review in Bad_Words for word in review])\n",
    "    \n",
    "    Overlap_User_Words = list(Good_Words.intersection(Bad_Words))\n",
    "    ```  \n",
    "    \n",
    "    2. For Y_{s}, create the following lists:\n",
    "    \n",
    "    ```python\n",
    "    Good_Reviews = [review for review in Y_{s} if rating(x) >= 4]\n",
    "    Bad_reviews = [review for review in Y_{s} if rating(x) < 4]\n",
    "    \n",
    "    Good_Words = [review.split(' ') for review in Good_User_Reviews]\n",
    "    Bad_Words = [review.split(' ') for review in Good_User_Reviews]\n",
    "    Good_Words = set([word for review in Good_Words for word in review])\n",
    "    Bad_Words = set([word for review in Bad_Words for word in review])\n",
    "    \n",
    "    Overlap_Words = list(Good_Words.intersection(Bad_Words))\n",
    "    ```     \n",
    "    \n",
    "    3. Remove all words in reviews of $B$ that are in the list Overlap_User_Words\n",
    "    4. Remove all words in reviews of $Y_{s}$ that are in the list Overlap_Words\n",
    "    5. Represent $B$ and $Y_{s}$ as LDA matrices using a loading of 25 topics over the entire corpus of reviews\n",
    "<br><br>\n",
    "2. **Train**:\n",
    "    1. Train each of our algorithms on $Y_{s}$\n",
    "    2. Each training point will be characterized by the tuple (Review as LDA Matrix, Restaurant Rating, Restaurant ID)\n",
    "    3. We use the following algorithms:\n",
    "        1. Random Forest\n",
    "        2. Bagged Decision Tree\n",
    "        3. Linear SVM\n",
    "        4. SVM\n",
    "        5. Multinomial Logit Classification\n",
    "    \n",
    "3. **Test:**\n",
    "    1. Our test set is the set of user reviews, $B$\n",
    "        1. Note: we can generate artificial sets of user reviews using combinations of existing user reviews\n",
    "    2. Try classifying the test set using all the different algorithms, pick the one that performs best at classifying the review's rating\n",
    "     3. Each element in the test set will have the form (User Review, Predicted Review Rating, Actual Review Rating, Predicted Restaurant) we choose the classifier that minimizes the **RSME** of the review rating classifications  \n",
    "\n",
    "4. **Report:**\n",
    "    3. Return the restaurant classification results from the classification algorithm that performs best as the list H1_Result\n",
    "        1. (User Review, Predicted Restaurant Rating, Actual Review Rating, Predicted Restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis 2 Algorithm Sketch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this algorithm sketch is to create a classification scheme using Hypothesis 2. We represent all the reviews in $B$ and $Y_{s}$ as tf-idf matrices, with the vocabulary defined using the H&L dictionary. Then we classify using the same machine learning algorithms as defined in Hypothesis 1.\n",
    "\n",
    "More formally, we want a mapping such that $f(B): B \\rightarrow \\text{Most tonally similiar R in } Y_{s}$\n",
    "    \n",
    "1. **Build**:\n",
    "    1. Create the following lists:\n",
    "    \n",
    "    ```python\n",
    "    Good_User_Reviews = [review for review in B if rating(review) >= 4]\n",
    "    Bad_User_reviews = [review for review in B if rating(review) < 4]\n",
    "    ```  \n",
    "    \n",
    "    ```python\n",
    "    Good_Reviews = [review for review in Y_{s} if rating(x) >= 4]\n",
    "    Bad_reviews = [review for review in Y_{s} if rating(x) < 4]\n",
    "    ```  \n",
    "    \n",
    "    1. Create a bag of words using the H&L dictionary for all reviews in $B$ and $Y_{s}$\n",
    "    2. Run TF-IDF on reviews in $B$ using the entire corpus\n",
    "    3. Run TF-IDF on reviews in $Y_{s}$ using the entire corpus\n",
    "  \n",
    "    \n",
    "2. **Train**:\n",
    "    1. We train each of our algorithms on the tf-idf representation of $Y_{s}$\n",
    "    2. Each training point will be characterized by the tuple (Review as TF-IDF Matrix, Restaurant Rating, Restaurant ID)\n",
    "    3. We use the following algorithms:\n",
    "        1. Random Forest\n",
    "        2. Bagged Decision Tree\n",
    "        3. Linear SVM\n",
    "        4. SVM\n",
    "        5. Multinomial Logit Classification\n",
    "        \n",
    "3. **Test:**\n",
    "    1. Our test set will be defined as all the user reviews, represented as tf-idf vectors defined over the H&L Dictionary\n",
    "        1. We can generate artificial sets of user reviews using combinations of existing user reviews \n",
    "    2. Try classifying the test set using all the different algorithms, pick the one that performs best\n",
    "        3. Each element in the test set will have the form (User Review, Actual Rating, Predicted Restaurant Rating, Predicted Restaurant), we choose the classifier that minimizes the **RSME** for our set of user reviews.\n",
    "\n",
    "4. **Report:**\n",
    "    3. Return the test results from the classification algorithm that performs best as the list H2_result\n",
    "         1. (User Review, Predicted Restaurant Rating, Actual Review Rating, Predicted Restaurant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a list of recommendations according to the following schema:  \n",
    "\n",
    "|            | _Same Tone_             | _Diff Tone_           |\n",
    "|------------|-----------------------|----------------------|\n",
    "| **_Same Word Choice_** | Yes                   | Max(Tone Classification, Word Classification) |\n",
    "| **_Diff Word Choice_** | Max(Tone Classification, Word Classification)  | No                   |\n",
    "\n",
    "After running the above algorithms, we'll have two sets of data:\n",
    "\n",
    "```python\n",
    "H1_Result = [(User Review,  Actual Review Rating, Restaurant Predicted by H1, Predicted Restaurant Rating)]\n",
    "H2_Result = [(User Review,  Actual Review Rating, Restaurant Predicted by H2, Predicted Restaurant Rating)]\n",
    "```\n",
    "\n",
    "Create the following list:\n",
    "\n",
    "```python\n",
    "    H1_Restaurants = list(set(Restaurants in H1_Result))\n",
    "    H2_Restaurants = list(set(Restaurants in H2_Result))\n",
    "    Restaurants = H1_Restaurants + H2_Restaurants\n",
    "```\n",
    "Run the following process to populate a 10 element recommendation list:\n",
    "\n",
    "```python\n",
    "Recommendation_list = []\n",
    "while len(Recommendation_list) < 10\n",
    "    for each restaurant in Restaurants:\n",
    "        if restaurant in both H1_Restaurant and H2_Restaurant:\n",
    "            Recommendation_list.append(restaurant)\n",
    "        else:\n",
    "          Draw X from a Uniform(0,1)\n",
    "          if restaurant in H1_Restaurant:\n",
    "              if X <= 0.6:  \n",
    "                  Recommendation_list.append(restaurant)\n",
    "              else:\n",
    "                  pass\n",
    "          else:\n",
    "              if X > 0.6:\n",
    "                  Recommendation_list.append(restaurant)\n",
    "              else:\n",
    "                  pass\n",
    "      \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So how do we test if this actually works?\n",
    "\n",
    "Whether or not a user likes a recommendation is hard to capture because we don't know if they like it or not until after we recommend it. In the above design, we'd be recommending a _new_ restaurant to the user. To see if they actually like it, we'd have to follow up after we make the recommendation and ask them how they felt. \n",
    "\n",
    "That is, we know $y_{pred}$ but we don't know $y_{actual}$. Following up on our recommendations isn't feasible since we don't have a set of people we can just ask how they felt.\n",
    "\n",
    "But we can get around this because sometimes a user review rating is also that user's restaurant rating. For a given user, if she only has one review for a restaurant then the rating for that review is also her rating for the restaurant.\n",
    "\n",
    "We can use this to test our recommendation system. Construct the following test design:\n",
    "\n",
    "**Build:**\n",
    "* As before, let $B$ be the total set of user reviews.\n",
    "* Let $R$ be the set of restaurants that the user has reviewed only once.\n",
    "* Take some percentage, $p$, of the set $R$ and let this be the set of test restaurants $R_{test}$.\n",
    "* Set the remaining $1-p$ percentage of the set $R$ and call this the training set of restaurants $R_{train}$. \n",
    "* Note every review in $R$ has Restaurant Rating = Review Rating\n",
    "\n",
    "**Run:**\n",
    "1. For each restaurant in $R_{test}$ find the corresponding review in $B$. Assign the tuple (User Review, Restaurant Rating, Restaurant ID) to the set $B_{test}$\n",
    "\n",
    "2. For each restaurant in $R_{train}$, find the total set of reviews from the Reviews database. Let this set be $Y$, where each element in $Y$ is a tuple (User Review, Restaurant Rating, Restaurant ID)\n",
    "\n",
    "3. We run each of the algorithms above, using $Y$ as the training set and $B_{test}$ as the test set.\n",
    "4. Step 3 results in a set $B_{result}$ where each element is characterized by (User Review, Actual Restaurant Rating, Predicted Restaurant Rating, Predicted Restaurant). Note the cardinality of $B_{result}$ is the same as that of $B_{test}$\n",
    "5. Set $y_{pred} =$ I(Predicted Restaurant) and $y_{actual} =$ I(Restaurant) where the indicator function I() is 1 if the user rated the restaurant at least a 4 and is 0 if the user rated the restaurant less than a 4\n",
    "6. The RMSE for the recommended restaurants is given by:\n",
    "\n",
    "$$RMSE = \\sum_{i=1}^{N} \\sqrt{\\frac{(y_{i, pred} - y_{i, actual})^{2}}{N}}$$\n",
    "\n",
    "Where N is the number of recommended restaurants (10) in $B_{result}$. $y_{i, pred}$ is the predicted restaurant rating, $y_{i, actual}$ is the actual rating that the user gave to the restaurant. A RSME score of 0 is a perfect score and means that the recommendation system did really well. In this case, success means that the recommendation system was able to accurately predict how the user would feel about the restaurant on a binary scale (good or bad).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So what?\n",
    "\n",
    "Well, if the RMSE above is low we can say with some confidence that our recommendation system is able to give out some good suggestions. We're going to operate under the assumption that people want to go to places that they'll like, not places that they'll likely hate.\n",
    "\n",
    "So to adjust the above, we need to throw out the bad classifications. That is, we only test on user reviews that are positive (i.e. they gave at least a rating of 4). The recommendations from this modification should only return restaurants that the user will probably like. \n",
    "\n",
    "We can run the above test on a bunch of different user comments and we can generate our own by writing some sample Yelp reviews. We might even be able to test it out in DC.\n",
    "\n",
    "Also, we can try scrapping for other cities. We already have a script written for DC, and it might make more sense to use \"live\" data rather than what's available in the Yelp dataset."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
