{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Tutorial\n",
    "\n",
    "The example below is taken from www.saedsayad.com/decision_tree.htm and a full (probably better) exposition of  how a decision tree works can be found there.\n",
    "\n",
    "We work with the following dataset:\n",
    "\n",
    "<img src = \"data_example.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the following entropic measures:\n",
    "\n",
    "$E(S) = \\sum_{i=1}^{c}-p_{i}\\log p_{i}$\n",
    "\n",
    "$E(S,X) = \\sum_{j=1}^{d \\in X}P(d)E(d)$\n",
    "\n",
    "Where $p_{i}$ is the empirical probability of event i happening and $P(d)$ is the empirical probability of event d occuring in the set of events defined over X.\n",
    "\n",
    "For example, the entropic measure of playing golf is given by the following:\n",
    "\n",
    "$E(Play Golf) = -P(No) * \\log_{2} P(No) - P(Yes) * \\log_{2} P(Yes) = - \\frac{5}{14} * \\log_{2} \\frac{5}{14} - \\frac{9}{14} * \\log_{2} \\frac{9}{14} \\approx 0.94$\n",
    "\n",
    "Note: in the above we use a log base of 2 because that's how large the decision space is, but all the results are the same if we use a log base of 10.\n",
    "\n",
    "The entropic measure of playing gold, conditioned on the outlook is given by:\n",
    "\n",
    "$E(Play Golf, Outlook) = P(Sunny) * \\log P(Play Golf| Sunny) + P(Overcast) * \\log P(Play Golf| Overcast) + P(Rainy) * \\log P(Play Golf| Rainy) = \\frac{5}{14} * (- \\frac{3}{5} * \\log_{2} \\frac{3}{5} - \\frac{2}{5} * \\log_{2} \\frac{2}{5}) + \\frac{4}{14} * (- \\frac{4}{4} * \\log_{2} \\frac{4}{4} - \\frac{0}{4} * \\log_{2} \\frac{0}{4}) + \\frac{5}{14} * (- \\frac{2}{5} * \\log_{2} \\frac{2}{5} - \\frac{3}{5} * \\log_{2} \\frac{3}{5}) \\approx 0.693$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Algorithm Steps\n",
    "\n",
    "##### Step 1. Calculate the entropy of the unconditioned dependent variable\n",
    "\n",
    "From above, we have that $E(PlayGolf) = 0.94$\n",
    "\n",
    "##### Step 2. Calculate the entropy associated with each feature and the dependent variable \n",
    "\n",
    "We have:\n",
    "\n",
    "$E(Play Golf, Outlook) = 0.94 - 0.247 = E(Play Golf) - Information Gain = 0.693$\n",
    "$E(Play Golf, Temperature) = Play Golf) - Information Gain = 0.94 - 0.029 = 0.911$\n",
    "$E(Play Golf, Humidity) = Play Golf) - Information Gain = 0.94 - 0.152 = 0.788$\n",
    "$E(Play Golf, Windy) = Play Golf) - Information Gain = 0.94 - 0.048 = 0.892$\n",
    "\n",
    "##### Step 3. Choose the feature with the lowest entropy, when included with the dependent variable, and divide the dataset based on its branches\n",
    "\n",
    "In the example above, we have that outlook is the  feature with the lowest associated Entropy with Playing Golf. Therefore, we divide the dataset as follows:\n",
    "\n",
    "<img src = \"outlook_split.JPG\">\n",
    "\n",
    "Note that the  branch with only Overcast has only \"Yes\" as a result for playing golf. This branch has an unconditioned entropy of 0. We call branches with 0 entropy \"leaf nodes\".\n",
    "\n",
    "##### Step 4. For branches with unconditioned entropy != 0, we condition on the other features and repeat steps 1 through 3 until we're left with only leaf nodes.\n",
    "\n",
    "In order to classify new sets of data, we use the decision tree that we've built on the training set and pass our test data through it. The data set will eventually end up in a leaf node with entropy 0, which tells us which class to place it in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on Kullbeck-Liebler Divergence \n",
    "\n",
    "KL-Divergence for two discrete distributions is defined as follows:\n",
    "\n",
    "<img src = \"KL_divergence.jpg\">\n",
    "\n",
    "In step 2 of the algorithm, we're looking at the \"information gain\" of convoluting on different features. But this is simply maximizing KL divergence by choosing the \"furtherest\" convoluted distribution from the unconvoluted distribution. To see this, consider the following:\n",
    "\n",
    "$\\sum_{x \\in X} p(x) \\log \\frac{p(x)}{q(x)} = \\sum_{x \\in X} p(x) (\\log p(x) - \\log q(x))$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
